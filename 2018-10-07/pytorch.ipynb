{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa61fdcd990>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np; from sklearn.datasets import load_iris\n",
    "import torch; import torch.nn as nn; import torch.nn.functional as F\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = np.random.randint(0, 150, size=50)\n",
    "X_train, X_test = torch.from_numpy(load_iris().data[~test_index]).type(torch.FloatTensor), torch.from_numpy(load_iris().data[test_index]).type(torch.FloatTensor)\n",
    "y_train, y_test = torch.from_numpy(load_iris().target[~test_index]).type(torch.LongTensor), torch.from_numpy(load_iris().target[test_index]).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jayme/miniconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5000] Loss: 1.2800\n",
      "Epoch [51/5000] Loss: 0.7638\n",
      "Epoch [101/5000] Loss: 0.6344\n",
      "Epoch [151/5000] Loss: 0.5505\n",
      "Epoch [201/5000] Loss: 0.4927\n",
      "Epoch [251/5000] Loss: 0.4493\n",
      "Epoch [301/5000] Loss: 0.4140\n",
      "Epoch [351/5000] Loss: 0.3836\n",
      "Epoch [401/5000] Loss: 0.3566\n",
      "Epoch [451/5000] Loss: 0.3322\n",
      "Epoch [501/5000] Loss: 0.3101\n",
      "Epoch [551/5000] Loss: 0.2899\n",
      "Epoch [601/5000] Loss: 0.2716\n",
      "Epoch [651/5000] Loss: 0.2551\n",
      "Epoch [701/5000] Loss: 0.2401\n",
      "Epoch [751/5000] Loss: 0.2268\n",
      "Epoch [801/5000] Loss: 0.2148\n",
      "Epoch [851/5000] Loss: 0.2041\n",
      "Epoch [901/5000] Loss: 0.1944\n",
      "Epoch [951/5000] Loss: 0.1858\n",
      "Epoch [1001/5000] Loss: 0.1779\n",
      "Epoch [1051/5000] Loss: 0.1709\n",
      "Epoch [1101/5000] Loss: 0.1645\n",
      "Epoch [1151/5000] Loss: 0.1588\n",
      "Epoch [1201/5000] Loss: 0.1536\n",
      "Epoch [1251/5000] Loss: 0.1488\n",
      "Epoch [1301/5000] Loss: 0.1445\n",
      "Epoch [1351/5000] Loss: 0.1406\n",
      "Epoch [1401/5000] Loss: 0.1370\n",
      "Epoch [1451/5000] Loss: 0.1337\n",
      "Epoch [1501/5000] Loss: 0.1306\n",
      "Epoch [1551/5000] Loss: 0.1278\n",
      "Epoch [1601/5000] Loss: 0.1253\n",
      "Epoch [1651/5000] Loss: 0.1229\n",
      "Epoch [1701/5000] Loss: 0.1207\n",
      "Epoch [1751/5000] Loss: 0.1186\n",
      "Epoch [1801/5000] Loss: 0.1167\n",
      "Epoch [1851/5000] Loss: 0.1150\n",
      "Epoch [1901/5000] Loss: 0.1133\n",
      "Epoch [1951/5000] Loss: 0.1118\n",
      "Epoch [2001/5000] Loss: 0.1103\n",
      "Epoch [2051/5000] Loss: 0.1090\n",
      "Epoch [2101/5000] Loss: 0.1077\n",
      "Epoch [2151/5000] Loss: 0.1066\n",
      "Epoch [2201/5000] Loss: 0.1054\n",
      "Epoch [2251/5000] Loss: 0.1044\n",
      "Epoch [2301/5000] Loss: 0.1034\n",
      "Epoch [2351/5000] Loss: 0.1025\n",
      "Epoch [2401/5000] Loss: 0.1016\n",
      "Epoch [2451/5000] Loss: 0.1008\n",
      "Epoch [2501/5000] Loss: 0.1000\n",
      "Epoch [2551/5000] Loss: 0.0992\n",
      "Epoch [2601/5000] Loss: 0.0985\n",
      "Epoch [2651/5000] Loss: 0.0979\n",
      "Epoch [2701/5000] Loss: 0.0972\n",
      "Epoch [2751/5000] Loss: 0.0966\n",
      "Epoch [2801/5000] Loss: 0.0961\n",
      "Epoch [2851/5000] Loss: 0.0955\n",
      "Epoch [2901/5000] Loss: 0.0950\n",
      "Epoch [2951/5000] Loss: 0.0945\n",
      "Epoch [3001/5000] Loss: 0.0940\n",
      "Epoch [3051/5000] Loss: 0.0936\n",
      "Epoch [3101/5000] Loss: 0.0931\n",
      "Epoch [3151/5000] Loss: 0.0927\n",
      "Epoch [3201/5000] Loss: 0.0923\n",
      "Epoch [3251/5000] Loss: 0.0920\n",
      "Epoch [3301/5000] Loss: 0.0916\n",
      "Epoch [3351/5000] Loss: 0.0913\n",
      "Epoch [3401/5000] Loss: 0.0909\n",
      "Epoch [3451/5000] Loss: 0.0906\n",
      "Epoch [3501/5000] Loss: 0.0903\n",
      "Epoch [3551/5000] Loss: 0.0900\n",
      "Epoch [3601/5000] Loss: 0.0897\n",
      "Epoch [3651/5000] Loss: 0.0894\n",
      "Epoch [3701/5000] Loss: 0.0892\n",
      "Epoch [3751/5000] Loss: 0.0889\n",
      "Epoch [3801/5000] Loss: 0.0887\n",
      "Epoch [3851/5000] Loss: 0.0885\n",
      "Epoch [3901/5000] Loss: 0.0882\n",
      "Epoch [3951/5000] Loss: 0.0880\n",
      "Epoch [4001/5000] Loss: 0.0878\n",
      "Epoch [4051/5000] Loss: 0.0876\n",
      "Epoch [4101/5000] Loss: 0.0874\n",
      "Epoch [4151/5000] Loss: 0.0872\n",
      "Epoch [4201/5000] Loss: 0.0870\n",
      "Epoch [4251/5000] Loss: 0.0869\n",
      "Epoch [4301/5000] Loss: 0.0867\n",
      "Epoch [4351/5000] Loss: 0.0865\n",
      "Epoch [4401/5000] Loss: 0.0864\n",
      "Epoch [4451/5000] Loss: 0.0862\n",
      "Epoch [4501/5000] Loss: 0.0860\n",
      "Epoch [4551/5000] Loss: 0.0859\n",
      "Epoch [4601/5000] Loss: 0.0858\n",
      "Epoch [4651/5000] Loss: 0.0856\n",
      "Epoch [4701/5000] Loss: 0.0855\n",
      "Epoch [4751/5000] Loss: 0.0854\n",
      "Epoch [4801/5000] Loss: 0.0852\n",
      "Epoch [4851/5000] Loss: 0.0851\n",
      "Epoch [4901/5000] Loss: 0.0850\n",
      "Epoch [4951/5000] Loss: 0.0849\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "hl = 10; lr = 0.01; num_epoch = 5000\n",
    "\n",
    "# model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, hl)\n",
    "        self.fc2 = nn.Linear(hl, 3)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "net = Net()\n",
    "\n",
    "# optimizer and loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "# train\n",
    "for epoch in range(num_epoch):  \n",
    "    #feedforward - backprop\n",
    "    optimizer.zero_grad()\n",
    "    out = net(X_train)\n",
    "    loss = criterion(out, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch) % 50 == 0:\n",
    "        print('Epoch [%d/%d] Loss: %.4f' %(epoch+1, num_epoch, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network 98 %\n"
     ]
    }
   ],
   "source": [
    "out = net(X_test)\n",
    "_, predicted = torch.max(out.data, 1)\n",
    "print('Accuracy of the network %d %%' % (100 * torch.sum(y_test==predicted) / 50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
